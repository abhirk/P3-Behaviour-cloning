{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import traceback\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "CSV_FILE=\"data/driving_log.csv\"\n",
    "IMG_DIR=\"data/IMG/\"\n",
    "STEERING_CORRECTION = 0.2\n",
    "\n",
    "images = []\n",
    "measurements = []\n",
    "\n",
    "\n",
    "def read_csv(filename):\n",
    "    with open(filename) as csvfile:\n",
    "        rd = csv.DictReader(csvfile, fieldnames=[\"Center\",\"Left\",\"Right\", \"Steering\", \"Throttle\", \"Brake\", \"Speed\"])\n",
    "        for row in rd:\n",
    "            center_image = cv2.imread(IMG_DIR + os.path.basename(row[\"Center\"]))\n",
    "            left_image = cv2.imread(IMG_DIR + os.path.basename(row[\"Left\"]))\n",
    "            right_image = cv2.imread(IMG_DIR + os.path.basename(row[\"Right\"]))\n",
    "\n",
    "            center_steering = float(row[\"Steering\"])\n",
    "            left_steering = center_steering + STEERING_CORRECTION\n",
    "            right_steering = center_steering - STEERING_CORRECTION\n",
    "            \n",
    "            flipped_center = np.fliplr(center_image)\n",
    "            flipped_steering = -center_steering\n",
    "            \n",
    "            images.extend([center_image, left_image, right_image, flipped_center])\n",
    "            measurements.extend([center_steering, left_steering, right_steering, flipped_steering])\n",
    "            \n",
    "\n",
    "def read_csv_list(filename):\n",
    "    with open(filename) as csvfile:\n",
    "        rd = csv.reader(csvfile)\n",
    "        for row in rd:\n",
    "            center_image = cv2.imread(IMG_DIR + os.path.basename(row[0]))\n",
    "            left_image = cv2.imread(IMG_DIR + os.path.basename(row[1]))\n",
    "            right_image = cv2.imread(IMG_DIR + os.path.basename(row[2]))\n",
    "\n",
    "            center_steering = float(row[3])\n",
    "            left_steering = center_steering + STEERING_CORRECTION\n",
    "            right_steering = center_steering - STEERING_CORRECTION\n",
    "\n",
    "            flipped_center = np.fliplr(center_image)\n",
    "            flipped_steering = -center_steering\n",
    "            \n",
    "            images.extend([center_image, left_image, right_image, flipped_center])\n",
    "            measurements.extend([center_steering, left_steering, right_steering, flipped_steering])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dataset....\n",
      "done\n",
      "(72500, 160, 320, 3)\n",
      "(72500, 160, 320, 3)\n",
      "CPU times: user 1min 58s, sys: 26.1 s, total: 2min 24s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Collecting dataset....\"),\n",
    "try:\n",
    "    read_csv(CSV_FILE)\n",
    "    X_train = np.array(images)\n",
    "    Y_train = np.array(measurements)\n",
    "except:\n",
    "    traceback.print_exc()\n",
    "print(\"done\")\n",
    "print(X_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kolhea/anaconda3/envs/tensorflow_gpu/lib/python3.5/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  '` call to the Keras 2 API: ' + signature)\n",
      "/Users/kolhea/anaconda3/envs/tensorflow_gpu/lib/python3.5/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  '` call to the Keras 2 API: ' + signature)\n",
      "/Users/kolhea/anaconda3/envs/tensorflow_gpu/lib/python3.5/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  '` call to the Keras 2 API: ' + signature)\n",
      "/Users/kolhea/anaconda3/envs/tensorflow_gpu/lib/python3.5/site-packages/keras/legacy/interfaces.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  '` call to the Keras 2 API: ' + signature)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: expected dense_7 to have shape (None, 10) but got array with shape (72500, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-adce6b738f20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kolhea/anaconda3/envs/tensorflow_gpu/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/kolhea/anaconda3/envs/tensorflow_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1406\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kolhea/anaconda3/envs/tensorflow_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1297\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m                                     exception_prefix='model target')\n\u001b[0m\u001b[1;32m   1300\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1301\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/Users/kolhea/anaconda3/envs/tensorflow_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    131\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model target: expected dense_7 to have shape (None, 10) but got array with shape (72500, 1)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Lambda, Flatten, Dense, Dropout\n",
    "from keras.layers import Cropping2D\n",
    "# from keras.layers.convolutional import Conv2D\n",
    "# from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "print(\"Training model...\")\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "#cropping default 50,20\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0)), input_shape=(160,320,3)))\n",
    "model.add(Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(Flatten()) #Flatten(input_shape=(160,320,3)\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X_train, Y_train, validation_split=0.2, shuffle=True)\n",
    "\n",
    "scores = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
